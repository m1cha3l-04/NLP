{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "\n",
    "### Stemming\n",
    "\n",
    "> **Stemming** is a technique used to reduce an inflected word down to its word stem. For example, the words “programming,” “programmer,” and “programs” can all be reduced down to the common word stem “program.” In other words, “program” can be used as a synonym for the prior three inflection words. \n",
    "\n",
    "### Advantages of Stemming\n",
    "1. **Improved model performance:** Stemming reduces the number of unique words that need to be processed by an algorithm, which can improve its performance. Additionally, it can also make the algorithm run faster and more efficiently.\n",
    "2. **Grouping similar words: Words** with a similar meaning can be grouped together, even if they have distinct forms. This can be a useful technique in tasks such as document classification, where it’s important to identify key topics or themes within a document. \n",
    "3. **Easier to analyze and understand:** Since stemming typically reduces the size of the vocabulary, it’s much easier to analyze, compare, and understand texts. This is helpful in tasks such as sentiment analysis, where the goal is to determine the sentiment of a document.\n",
    "\n",
    "### Disadvantages of Stemming\n",
    "1. **Overstemming / False positives:** This is when a stemming algorithm reduces separate inflected words to the same word stem even though they are not related; for example, the Porter Stemmer algorithm stems  \"universal\", \"university\", and \"universe\" to the same word stem. Though they are etymologically related, their meanings in the modern day are from widely different domains. Treating them as synonyms will reduce relevance in search results. \n",
    "2. **Understemming / False negatives:** This is when a stemming algorithm reduces inflected words to different word stems, but they should be the same. For example, the Porter Stemmer algorithm does not reduce the words “alumnus,” “alumnae,” and “alumni” to the same word stem, although they should be treated as synonyms. \n",
    "3. **Language challenges:** As the target language's morphology, spelling, and character encoding get more complicated, stemmers become more difficult to design; For example, an Italian stemmer is more complicated than an English stemmer because there is a higher number of verb inflections. A Russian stemmer is even more complex due to more noun declensions.\n",
    "\n",
    "### Lemmatization\n",
    "\n",
    "> **Lemmatization** is another technique used to reduce inflected words to their root word. It describes the algorithmic process of identifying an inflected word’s “lemma” (dictionary form) based on its intended meaning. \n",
    "\n",
    "### Advantages of Lemmatization\n",
    "- **Accuracy:** Lemmatization does not merely cut words off as you see in stemming algorithms. Analysis of words is conducted based on the word’s POS to take context into consideration when producing lemmas. Also, lemmatization leads to real dictionary words being produced.\n",
    "\n",
    "###Disadvantages of Lemmatization \n",
    "- **Time-consuming:** Compared to stemming, lemmatization is a slow and time-consuming process. This is because lemmatization involves performing morphological analysis and deriving the meaning of words from a dictionary.\n",
    "\n",
    "source: [datacamp.com](https://www.datacamp.com/tutorial/stemming-lemmatization-python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | ate\n",
      "adjustable | adjust\n",
      "rafting | raft\n",
      "ability | abil\n",
      "meeting | meet\n"
     ]
    }
   ],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "ate  |  eat\n",
      "adjustable  |  adjustable\n",
      "rafting  |  raft\n",
      "ability  |  ability\n",
      "meeting  |  meeting\n",
      "better  |  well\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Michael talked for 2 hours although talking isn't his thing\")\n",
    "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sis | Sis\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Sistah | Sistah\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Sis, you wanna go? Sistah, don't say no! I am exhausted\")\n",
    "for token in doc:\n",
    "    print(token.text, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sis | Sister\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Sistah | Sister\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "\n",
    "ar.add([[{\"TEXT\":\"Sis\"}],[{\"TEXT\":\"Sistah\"}]],{\"LEMMA\":\"Sister\"})\n",
    "\n",
    "doc = nlp(\"Sis, you wanna go? Sistah, don't say no! I am exhausted\")\n",
    "for token in doc:\n",
    "    print(token.text, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sistah"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sister'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
